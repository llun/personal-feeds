{"title":"Facebook’s Misinformation Addiction","link":"https://www.technologyreview.com/2021/03/11/1020600/facebook-responsible-ai-misinformation/","date":1616534446000,"content":"\n<p>One more on Facebook, this one a staggeringly well-reported piece by Karen Hao for MIT Technology Review, profiling Joaquin Quiñonero Candela, a director of AI at Facebook:</p>\n\n<blockquote>\n  <p>By the time thousands of rioters stormed the US Capitol in\nJanuary, organized in part on Facebook and fueled by the lies\nabout a stolen election that had fanned out across the platform,\nit was clear from my conversations that the Responsible AI team\nhad failed to make headway against misinformation and hate speech\nbecause it had never made those problems its main focus. More\nimportant, I realized, if it tried to, it would be set up for\nfailure.</p>\n\n<p>The reason is simple. Everything the company does and chooses not\nto do flows from a single motivation: Zuckerberg’s relentless\ndesire for growth. Quiñonero’s AI expertise supercharged that\ngrowth. His team got pigeonholed into targeting AI bias, as I\nlearned in my reporting, because preventing such bias helps the\ncompany avoid <a href=\"https://www.technologyreview.com/2019/04/15/1136/congress-wants-to-protect-you-from-biased-algorithms-deepfakes-and-other-bad-ai/\">proposed regulation</a> that might, if passed,\nhamper that growth. Facebook leadership has also repeatedly\nweakened or halted many initiatives meant to clean up\nmisinformation on the platform because doing so would undermine\nthat growth.</p>\n</blockquote>\n\n<p>Later:</p>\n\n<blockquote>\n  <p>Since then, other employees have corroborated these findings. A\nformer Facebook AI researcher who joined in 2018 says he and his\nteam conducted “study after study” confirming the same basic idea:\nmodels that maximize engagement increase polarization. They could\neasily track how strongly users agreed or disagreed on different\nissues, what content they liked to engage with, and how their\nstances changed as a result. Regardless of the issue, the models\nlearned to feed users increasingly extreme viewpoints. “Over time\nthey <em>measurably</em> become more polarized,” he says.</p>\n</blockquote>\n\n<p>It’s about priorities: even if Facebook truly wants to tamp down on misinformation and polarizing content (and I believe they do) it doesn’t matter if that desire is a lower priority for the company than increasing engagement (and I’m quite certain it is). Whether Facebook’s priorities are the company’s or Zuckerberg’s is probably indistinguishable. Such is the power of the founder/CEO. Apple/Jobs, Microsoft/Gates, Amazon/Bezos — all in the same boat.</p>\n\n<p>I know that “<em>Facebook is a shitty company doing harm to the world</em>” stories are getting old, but this one is truly worth setting aside to read with your full attention.</p>\n\n<div>\n<a  title=\"Permanent link to ‘Facebook’s Misinformation Addiction’\"  href=\"https://daringfireball.net/linked/2021/03/23/facebook-misinformation\">&nbsp;★&nbsp;</a>\n</div>\n\n\t","author":"John Gruber","siteTitle":"Daring Fireball","siteHash":"fc569638025dadf22a867470f8215f38855cf50e975782a6c989909474292a36","entryHash":"ba7dcb3cc05c8ac31f2c0fadaa08eb0d55c3ecdf8656a7ea6036d16a1bba8f8c","category":"Tech"}
{"title":"New Auto Scaling Strategy with HashiCorp Nomad","link":"https://www.hashicorp.com/blog/new-auto-scaling-strategy-with-hashicorp-nomad","date":1620316800000,"content":"<p>The <a href=\"https://www.nomadproject.io/docs/autoscaling\">Nomad Autoscaler</a> enables automated application and cluster scaling of your Nomad workloads and infrastructure. Adapting quickly to changes is crucial for serving users and meeting business goals and requirements. Cluster scaling can also help reduce infrastructure costs and remove the manual work that slows down your team.</p>\n<p>In its latest release as part of the <a href=\"https://www.hashicorp.com/blog/announcing-hashicorp-nomad-1-1-beta\">Nomad 1.1 beta</a>, the Nomad Autoscaler brings new plugins and capabilities that aim to expand when and where autoscaling can be used, making it easier to apply it in different scenarios and use cases.</p>\n<h2><a href=\"#new-plugins\">»</a><a></a>New Plugins</h2>\n<p>The Nomad Autoscaler relies on <a href=\"https://www.nomadproject.io/docs/autoscaling/plugins\">plugins</a> to do its work. Some plugins are pre-packaged within the Autoscaler, while others are contributed by the community and can be installed externally.</p>\n<p>There are three types of plugins:</p>\n<ul>\n<li><strong>APM plugins</strong> query and retrieve metrics from application performance monitoring systems.</li>\n<li><strong>Strategy plugins</strong> calculate what changes the Autoscaler must do to meet the policy defined by operators.</li>\n<li><strong>Target plugins</strong> apply the changes specified by the Autoscaler into infrastructure components.</li>\n</ul><img src=\"https://www.datocms-assets.com/2885/1620250038-nomadclusterautoscaler.jpg\" /><p><em>Nomad cluster autoscaling on three major clouds</em></p>\n<p>Since the beginning of the year, we and our community have added several new plugins to the Nomad Autoscaler. Most notably were the community contributions for <a href=\"https://github.com/hashicorp/nomad-autoscaler/pull/353\">Google Cloud managed instance groups</a> and <a href=\"https://github.com/hashicorp/nomad-autoscaler/pull/278\">Microsoft Azure virtual machine scale sets</a> targets, which are built-in plugins released in v0.3.0 and v0.2.0 respectively, and external target plugins for <a href=\"https://github.com/jsiebens/nomad-droplets-autoscaler\">DigitalOcean droplets</a> and <a href=\"https://github.com/dkt26111/nomad-senlin-autoscaler\">OpenStack Senlin</a>.</p>\n<p>The latest releases also include new strategy plugins that are better suited for situations where the existing <code>target-value</code> strategy is not a good fit. This makes it easier to construct and reason about scaling policies. In the next sections we will describe how these new plugins work, and when and how to use them.</p>\n<h3><a href=\"#fixed-value-strategy\">»</a><a></a>Fixed Value Strategy</h3>\n<p>This is a very simple strategy: it always returns the same predefined value set in the policy. By itself, it doesn't seem very useful, but when used with other checks within the same scaling policy it provides a simple mechanism to define a baseline for your infrastructure.</p>\n<p>Since the value returned is always the same, it's not necessary to define the metric source and query.</p><pre><code>job \"app\" {\n  # ...\n  group \"webapp\" {\n    # ...\n    scaling {\n      min = 1\n      max = 10\n\n      policy {\n        check \"fixed\" {\n          strategy \"fixed-value\" {\n            value = 4\n          }\n        }\n\n        check \"dynamic\" {\n          source = \"prometheus\"\n          query  = \"...\"\n\n          strategy \"target-value\" {\n            target = 10\n          }\n        }\n      }\n      # ...\n    }\n  }\n}</code></pre><p>In the example above, the <code>fixed</code> check effectively defines that at least four allocations will be running at a given time. The <code>dynamic</code> check is allowed to generate other values, but if the result is below four, the <code>fixed</code> check will take precedence.</p>\n<p>While this is a contrived example, future releases of the Nomad Autoscaler will include new functionalities to take full advantage of this strategy.</p>\n<h3><a href=\"#pass-through-strategy\">»</a><a></a>Pass-Through Strategy</h3>\n<p>The <code>pass-through</code> strategy is also very simple in principle, but very powerful in practice. It doesn't add any extra logic on top of the metric query result, which allows for the resulting scaling action to be calculated externally. Since the change factor is already known, there is nothing more for the Autoscaler to do other than apply the desired value.</p>\n<p>As an example, imagine a batch job that requires special hardware to run, such as a large amount of memory or expensive GPU units. In a cloud environment, where these resources can be provisioned on-demand and paid for by the hour, it is costly to keep them running when there are no jobs to process. It is also counterproductive to manually provision them when needed.</p>\n<p>Using the new <code>pass-through</code> strategy it is possible to define a horizontal cluster scaling policy that creates only as many instances as there are batch jobs in-progress.</p><pre><code>scaling \"batch_processing_cluster\" {\n  min = 0\n  max = 20\n\n  policy {\n\tcheck \"batch_jobs_in_progress\" {\n  \tsource = \"prometheus\"\n\n  \t# Sum the number of batch jobs that are running or pending.\n  \tquery = \"sum(nomad_nomad_job_summary_queued{exported_job=~\\\"batch/.*\\\"} + nomad_nomad_job_summary_running{exported_job=~\\\"batch/.*\\\"})\"\n\n  \tstrategy \"pass-through\" {}\n\t}\n\n\ttarget \"aws-asg\" {\n  \taws_asg_name = \"batch_clients\"\n  \tnode_class   = \"high_memory\"\n\t}\n  }\n}</code></pre><h3><a href=\"#threshold-strategy\">»</a><a></a>Threshold Strategy</h3>\n<p>Using the existing <code>target-value</code> strategy, your infrastructure will closely match the dynamics of your metric. This can be undesirable for volatile time series, such as CPU usage, and hard to rationalize how the Nomad Autoscaler will react.</p>\n<p>The <code>threshold</code> strategy allows policies to define tiers with upper and lower bound values, and what action to take when the metric crosses into one of these tiers. The type of action can be a percentage change, a value delta, or a new absolute value.</p>\n<p>Here is a cluster scaling policy that defines what action to take based on overall cluster CPU usage.</p><pre><code>scaling \"cluster_scaling\" {\n  min = 1\n  max = 10\n\n  policy {\n    check \"high_cpu_usage\" {\n      source = \"prometheus\"\n      query  = \"avg(nomad_client_host_cpu_total)\"\n\n      strategy \"threshold\" {\n        # If CPU usage goes above 70%...\n        upper_bound = 100\n        lower_bound = 70\n\n        # ...add one instance.\n        delta = 1\n      }\n    }\n\n    check \"low_cpu_usage\" {\n      source = \"prometheus\"\n      query  = \"avg(nomad_client_host_cpu_total)\"\n\n      strategy \"threshold\" {\n        # If CPU usage goes below 30%...\n        upper_bound = 30\n        lower_bound = 0\n\n        # ...remove one instance.\n        delta = 1\n      }\n    }\n\n    target \"aws-asg\" {\n  \t# ...\n    }\n  }\n}</code></pre><h2><a href=\"#better-cluster-scale-in-control\">»</a><a></a>Better Cluster Scale-In Control</h2>\n<p>When the Nomad Autoscaler detects that a cluster can be reduced, it performs a scale-in action to drain and decommission Nomad clients. The first releases of the Autoscaler would simply pick clients in the order returned by the Nomad API. While this works for some applications, it can be quite disruptive for others that require allocations to run to completion.</p>\n<p>A new policy target attribute called <code>node_selector_strategy</code> allows changing this client selection mechanism to an option that better fits the types of workloads running in the cluster. There are four strategies to pick from:</p>\n<ul>\n<li>\n<a></a>\n<a href=\"#least_busy\"><code>least_busy</code></a> prioritizes clients with the lowest amount of CPU and memory allocated, and it is the new default.</li>\n<li>\n<a></a>\n<a href=\"#empty\"><code>empty</code></a> only selects clients that have no allocations running.</li>\n<li>\n<a></a>\n<a href=\"#empty_ignore_system\"><code>empty_ignore_system</code></a> is similar to the <code>empty</code> strategy but ignores allocations from system jobs.</li>\n<li>\n<a></a>\n<a href=\"#newest_create_index\"><code>newest_create_index</code></a> is the previous default behavior and uses the same ordering as returned from the Nomad API.</li>\n</ul>\n<h2><a href=\"#new-learn-tutorials\">»</a><a></a>New Learn Tutorials</h2>\n<p>To help demonstrate how these new features work, we released new tutorials in our HashiCorp Learn portal. Head over to the <a href=\"https://learn.hashicorp.com/collections/nomad/autoscaler\">Autoscaling</a> section to access them.</p>\n<p>More details about the <a href=\"https://www.nomadproject.io/docs/autoscaling/plugins\">new plugins</a> and <a href=\"https://www.nomadproject.io/docs/autoscaling/internals/node-selector-strategy\">node selector strategies</a> can be found on our website.</p>\n<h2><a href=\"#what-s-next\">»</a><a></a>What's Next</h2>\n<p>Autoscaling is a crucial part of modern infrastructure, and it must be a fast and reliable process. For the next releases of the Nomad Autoscaler we will be focusing on production readiness, building highly anticipated features such as high-availability deployments, crash recovery, and improved visibility of what is happening with the <a href=\"https://github.com/hashicorp/nomad-autoscaler/\">Autoscaler</a>.</p>\n<p>We would like to thank our community for all the contributions, feature requests and bug reports that allowed us to reach this point. You all help us improve with each release.</p>","author":"Luiz Gustavo Ferraz Aoqui","siteTitle":"HashiCorp Blog","siteHash":"219aa6310b3388f2335eba49871f4df9581f2c58eaeb5e498363b54e835b7001","entryHash":"0ac15d9ef295bea41f7e06ec8787d19ba33fa5c4b5fa13f7e1cba9cf2c2a8979","category":"Tech"}
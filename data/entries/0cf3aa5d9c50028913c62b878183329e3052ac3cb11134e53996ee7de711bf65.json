{"title":"Automated Canary Deployment with HashiCorp Consul and Spinnaker","link":"https://www.hashicorp.com/blog/automated-canary-deployment-with-hashicorp-consul-and-spinnaker","date":1619118000000,"content":"<p>When you update an application or system, you likely push the changes to production and manually verify whether or not it works. If the changes fail, they could have a wide impact across your system and users. Instead, you can use a <a href=\"https://martinfowler.com/bliki/CanaryRelease.html\">canary deployment</a> to send a small percentage of traffic to new versions of an application or system. This reduces the blast radius of any problems because you can check if the change failed with a smaller subset of users. But canary deployments often require someone to analyze application metrics and then manually increase the percentage of traffic to the new application. A manual canary deployment can take days, especially if you need to wait for more data before increasing traffic!</p>\n<p>This post will show how to automate a canary analysis and deployment of an application with <a href=\"https://spinnaker.io\">Spinnaker</a> canary analysis, <a href=\"https://prometheus.io\">Prometheus</a> metrics, and <a href=\"https://www.consul.io/\">HashiCorp Consul</a> service mesh. Spinnaker, a continuous delivery framework, can control an application’s rollout based on the error rate reported by the service mesh’s proxies. While this example uses Kubernetes and Spinnaker, you can apply a similar approach to other workload orchestrators and continuous delivery platforms as long as you can configure Consul and analyze metrics.</p>\n<blockquote>\n<p><strong>Note:</strong> The configurations in this post use Consul 1.9 and Spinnaker 1.24. Download the <a href=\"https://github.com/joatmon08/spinnaker-consul\">example code</a> for detailed configuration.</p>\n</blockquote>\n<p>Let’s examine an example of a successful canary deployment. In the short video below, the percentage of traffic to the canary version increments each time the analysis stages pass. After all of the stages pass and the canary serves 100% of the traffic, the pipeline sets a new baseline version based on the canary.</p><p>The next video reviews a failed canary deployment. Imagine you deploy a canary version of an application with a minor bug. The first canary stage sends only 10% of traffic to the application. It recognizes the increased error for the application during analysis. The pipeline mitigates the failed change by sending 100% of traffic back to the baseline version.</p><h2><a href=\"#deploy-consul\">»</a><a></a>Deploy Consul</h2>\n<p>You need to register your services to a service mesh before you release it using a canary deployment. You can use HashiCorp Consul to generate proxy metrics and Prometheus to collect them. Consul uses proxies to manage and shape traffic between services. The proxies can collect telemetry on requests to services. Review our <a href=\"https://learn.hashicorp.com/tutorials/consul/kubernetes-layer7-observability\">tutorial on using Prometheus and Consul service mesh</a> for a more detailed explanation of sending Consul’s proxy metrics to Prometheus.</p>\n<p>The <a href=\"https://github.com/hashicorp/consul-helm\">Consul Helm chart</a> creates a Consul server, clients, controller, injector, and UI. The <code>values.yaml</code> required version 0.31.1 or higher of the Consul Helm chart. This chart version enables the metrics configuration and deploys Prometheus as part of the installation:</p><pre><code>global:\n name: consul\n datacenter: kubernetes\n metrics:\n   enabled: true\n\nprometheus:\n enabled: true\n\nserver:\n replicas: 1\n\nclient:\n enabled: true\n\nconnectInject:\n enabled: true\n\ncontroller:\n enabled: true</code></pre><blockquote>\n<p><strong>Note:</strong> This configuration does not set up Consul ACLs or a secure configuration on Kubernetes. For more detailed information, refer to our <a href=\"https://learn.hashicorp.com/tutorials/consul/kubernetes-secure-agents\">Learn tutorial</a>.</p>\n</blockquote>\n<p>Add the HashiCorp Helm chart repository:</p><pre><code>$ helm repo add hashicorp https://helm.releases.hashicorp.com</code></pre><p>Check the chart version is 0.31.1 or higher:</p><pre><code>$ helm search repo hashicorp/consul\n\nNAME                    CHART VERSION   APP VERSION     DESCRIPTION                    \nhashicorp/consul        0.31.1          1.9.4           Official HashiCorp Consul Chart</code></pre><p>Run Helm to install the Consul cluster and Prometheus server:</p><pre><code>$ helm install consul hashicorp/consul -f values.yaml</code></pre><p>After you deploy Consul to the cluster, you can access the Consul UI locally on <a href=\"http://localhost:8500\">http://localhost:8500</a> with Kubernetes port forwarding:</p><pre><code>$ kubectl port-forward svc/consul-ui 8500:80</code></pre><p>To add the dashboards for request metrics, install the <a href=\"https://github.com/grafana/helm-charts/tree/main/charts/grafana\">Grafana Helm chart</a>:</p><pre><code>$ helm repo add grafana https://grafana.github.io/helm-charts</code></pre><p>Deploy Grafana using the Helm <a href=\"https://github.com/joatmon08/spinnaker-consul/blob/main/kubernetes/raw/grafana.yaml\">values for this example</a>. They include a pre-fabricated dashboard that will be loaded into Grafana:</p><pre><code>adminPassword: password\n\ndatasources:\n datasources.yaml:\n   apiVersion: 1\n   datasources:\n   - name: Prometheus\n     type: prometheus\n     url: http://prometheus-server\n     access: proxy\n     isDefault: true\n\ndashboardProviders:\ndashboardproviders.yaml:\n  apiVersion: 1\n  providers:\n  - name: 'default'\n    orgId: 1\n    folder: ''\n    type: file\n    disableDeletion: false\n    editable: true\n    options:\n      path: /var/lib/grafana/dashboards/default\n\ndashboards:\n default:\n   app:\n     json: |\n       {\n         \"annotations\": {\n         # omitted for clarity</code></pre><p>After you deploy Grafana to the cluster, you can access the Grafana dashboard locally on <a href=\"http://localhost:3000\">http://localhost:3000</a> with Kubernetes port forwarding. Log in with the username <code>admin</code> and the password <code>password</code>:</p><pre><code>$ kubectl port-forward svc/grafana 3000:80</code></pre><p>You’ll find a <a href=\"http://localhost:3000/d/apps/applications\">dashboard</a> named “Applications” that will eventually display request metrics for Consul services:</p><img src=\"https://www.datocms-assets.com/2885/1619019174-consulgrafanaempty.png\" /><p>Before you deploy the example application, set the default configuration for Consul’s proxies. You can use Kubernetes <a href=\"https://www.consul.io/docs/connect/config-entries/proxy-defaults\">CustomResourceDefinitions for proxy defaults</a>. The proxies use <code>http</code> as the default protocol and write metrics to Prometheus. Save this file as <code>proxydefaults.yaml</code>:</p><pre><code>apiVersion: consul.hashicorp.com/v1alpha1\nkind: ProxyDefaults\nmetadata:\n  name: global\nspec:\n  config:\n    protocol: http\n    envoy_prometheus_bind_addr: \"0.0.0.0:9102\"'</code></pre><p>Apply <code>proxydefaults.yaml</code> to your Kubernetes cluster:</p><pre><code>$ kubectl apply -f proxydefaults.yaml</code></pre><h2><a href=\"#deploy-example-applications\">»</a><a></a>Deploy Example Applications</h2>\n<p>This demonstration uses two services named “ui” and “web”. Both services use Consul service mesh. All traffic from the “ui” service goes to the baseline version of “web”. The proxies for each service collect metrics for requests and responses without additional telemetry added to the application code.</p><img src=\"https://www.datocms-assets.com/2885/1619022062-spinnaker-prometheus-consul.png\" /><p>You can find the manifests for the applications in this post within the <a href=\"https://github.com/joatmon08/spinnaker-consul/tree/main/kubernetes/raw\">example code</a>. After you deploy the services, access the “ui” service through its Kubernetes load balancer configuration on port 9090:</p><pre><code>$ kubectl get services ui --output jsonpath='{.status.loadBalancer.ingress[0].ip}'</code></pre><p>You can also use the Consul UI’s topology view to verify that “ui” connects to the “web” service:</p><img src=\"https://www.datocms-assets.com/2885/1619022183-consulcanaryui.png\" /><p>Now that you’ve deployed a baseline, release a new version of the “web” service. Call it the “canary” release. You’ll use a canary deployment to send a small percentage of traffic to the canary release, analyze for any errors, and continue the rollout if requests succeed. You can configure Spinnaker to retrieve the proxy metrics for successful requests and errors to the “web” service and monitor the status of the canary.</p>\n<h2><a href=\"#deploy-spinnaker\">»</a><a></a>Deploy Spinnaker</h2>\n<p>Spinnaker uses a command-line tool called <a href=\"https://spinnaker.io/setup/install/halyard/\">Halyard</a> for deployment and configuration. The example configures a Spinnaker instance to target a Kubernetes cluster and use <a href=\"https://spinnaker.io/setup/install/storage/minio/\">Minio as the storage service</a>. You can choose your own target platform and storage source for your Spinnaker instance.</p>\n<p>In Spinnaker, enable <a href=\"https://spinnaker.io/setup/canary/\">canary analysis support</a> for Prometheus:</p><pre><code># May be optional depending on your Spinnaker version\n\n$ hal config features edit --mine-canary true\n\n$ hal config canary prometheus enable</code></pre><p>The canary account in Spinnaker must reference the Prometheus server and store analysis data into Minio. Set the <code>MINIO_SECRET_KEY</code>, <code>MINIO_ACCESS_KEY</code>, and <code>ENDPOINT</code> environment variables based on your Minio deployment:</p><pre><code>$ export MINIO_ACCESS_KEY=$(kubectl get -n storage secret s3-storage -o jsonpath=\"{.data.accesskey}\" | base64 --decode)\n\n$ export MINIO_SECRET_KEY=$(kubectl get -n storage secret s3-storage -o jsonpath=\"{.data.secretkey}\" | base64 --decode)\n\n$ export ENDPOINT=http://s3-storage.storage.svc.cluster.local:9000</code></pre><p>Configure the default metrics store and account for canary analysis:</p><pre><code>$ hal config canary prometheus account edit metrics \\ \n--base-url http://loki-prometheus-server.default.svc.cluster.local\n\n$ echo $MINIO_SECRET_KEY | hal config canary aws account \\\nedit minio --bucket spin-bucket --endpoint $ENDPOINT \\\n--access-key-id $MINIO_ACCESS_KEY --secret-access-key\n\n$ hal config canary aws edit --s3-enabled=true\n\n$ hal config canary edit --default-metrics-store prometheus\n\n$ hal config canary edit --default-metrics-account metrics\n\n$ hal config canary edit --default-storage-account minio</code></pre><p>Deploy Spinnaker on your Kubernetes cluster. It will take some time to create the components in the <code>spinnaker</code> namespace:</p><pre><code>$ hal deploy apply\n\n...\n+ Deploy spin-rosco  Success\n+ Run `hal deploy connect` to connect to Spinnaker.</code></pre><p>Connect to Spinnaker on Kubernetes. Spinnaker exposes its UI on port 9000 and API on 8084. Keep this terminal session open to configure your Spinnaker pipelines:</p><pre><code>$ hal deploy connect\n\n+ Get current deployment\n  Success\n+ Connect to Spinnaker deployment.\n  Success\nForwarding from 127.0.0.1:9000 -&gt; 9000\nForwarding from [::1]:9000 -&gt; 9000\nForwarding from 127.0.0.1:8084 -&gt; 8084\nForwarding from [::1]:8084 -&gt; 8084</code></pre><p>Spinnaker uses <a href=\"https://netflixtechblog.com/automated-canary-analysis-at-netflix-with-kayenta-3260bc7acc69\">Kayenta</a> to analyze metrics for canary deployments. You must enable the “Canary” setting under each Spinnaker application’s configuration to use the feature.</p><img src=\"https://www.datocms-assets.com/2885/1619023941-consulapplicationconfig.png\" /><p>Initialize the Spinnaker application and canary configuration using the <a href=\"https://spinnaker.io/guides/spin/\"><code>spin</code> command-line interface</a>. Make sure you can access the Spinnaker API on <a href=\"http://localhost:8084\">http://localhost:8084</a> and download the <a href=\"https://github.com/joatmon08/spinnaker-consul\">example repository</a>.</p>\n<p>Create the Spinnaker application named “web”. This groups any pipelines related to a particular application:</p><pre><code>$ spin application save -f spinnaker/application.json</code></pre><p>Apply the Spinnaker <a href=\"https://spinnaker.io/guides/user/canary/config/\">canary configuration</a> to the “web” application. This already includes the metrics and analysis configuration for the “web” canary release:</p><pre><code>$ spin canary canary-config save --file spinnaker/canary-config.json</code></pre><p>When you examine the canary configuration in the Spinnaker UI, you will notice that it analyzes Envoy metrics from the “web” service:</p><img src=\"https://www.datocms-assets.com/2885/1619024054-consulspinnakercanaryconfig.png\" /><p>The canary metric group analyzes the <code>envoy_cluster_upstream_rq_xx</code> metric from Prometheus. This metric counts the number of requests to the service and organizes them based on response code. For this example, you want to analyze requests from upstream for any HTTP 5XX response code, noted by the metric attribute <code>envoy_response_code_class=”5”</code>.</p>\n<p>Use a <a href=\"https://spinnaker.io/guides/user/canary/config/filter_templates/\">filter template</a> to select only metrics based on the “web” service, its release (defined by Spinnaker <code>scope</code>), and Kubernetes namespace (defined by Spinnaker <code>location</code>). By mapping the release to <code>scope</code> and namespace to <code>location</code>, you can pass attributes from the Spinnaker pipeline stage to the filter template:</p><pre><code>app=\"web\",envoy_response_code_class=\"5\",release=\"${scope}\",kubernetes_namespace=\"${location}\"</code></pre><p>If the metric increases over a pipeline’s analysis period, it will contribute to the overall score to determine if the canary deployment can continue. For “NaN Strategy”, choose “Replace with zero” to replace null data points with zero. You need to do this because <code>envoy_cluster_upstream_rq_xx</code> defaults to no data until the proxy receives a specific HTTP response code class:</p><img src=\"https://www.datocms-assets.com/2885/1619025281-config-metric-spinnaker.png\" /><p>The example uses a single metric to score the canary deployment. You can add more metrics for analysis and change the weight of each metric group under “Scoring”.</p>\n<h2><a href=\"#configure-spinnaker-pipeline\">»</a><a></a>Configure Spinnaker Pipeline</h2>\n<p>You’ll create a Spinnaker pipeline that uses a <strong>side-by-side</strong> canary deployment. This deploys a new version of the service and gradually cuts over traffic from baseline to canary version. You can also use Spinnaker for a rolling canary deployment, which scales up and down the individual service instances.</p>\n<p>Create the pipelines for deploying and deleting the “web” service with the <code>spin</code> CLI. Make sure you can access the Spinnaker API on <a href=\"http://localhost:8084\">http://localhost:8084</a> and download the <a href=\"https://github.com/joatmon08/spinnaker-consul\">example repository</a>:</p><pre><code>$ spin pipeline save -f spinnaker/deploy.json\n\n$ spin pipeline save -f spinnaker/delete.json</code></pre><p>Spinnaker will have two pipelines, one to run the canary deployment for the “web” service and another to delete it.</p><img src=\"https://www.datocms-assets.com/2885/1619025548-consulspinnakerpipelines.png\" /><p>Spinnaker will analyze Consul’s proxy metrics from Prometheus and generate a score during canary analysis stages. You set the canary configuration to watch for increases in the error rate to the “web” service. If the canary analysis passes, Spinnaker updates Consul to increase the percentage of the traffic to the canary release.</p><img src=\"https://www.datocms-assets.com/2885/1619025664-spinnaker-traffic.png\" /><p>The “Deploy” pipeline contains alternating stages that analyze the canary, check the score, and increase the traffic split. Each time the analysis passes, the pipeline increases traffic to the canary version. If the analysis fails, it rolls back the deployment by resetting 100% of traffic to the baseline version and 0% to the canary version:</p><img src=\"https://www.datocms-assets.com/2885/1619025717-consulspinnakerdeploypipeline.png\" /><p>How does the pipeline control traffic splitting between the baseline and canary versions? Spinnaker updates the Consul <a href=\"https://www.consul.io/docs/connect/config-entries/service-splitter\">service splitter</a> to shape traffic between baseline and canary versions. During the canary stages, Spinnaker applies a pre-defined text manifest that updates the service weights. For example, the “10% Canary” stage updates the service splitter to send 90% of traffic to baseline and 10% to canary:</p><pre><code>apiVersion: consul.hashicorp.com/v1alpha1\nkind: ServiceSplitter\nmetadata:\n  name: web\nspec:\n  splits:\n    - serviceSubset: baseline\n      weight: 90\n    - serviceSubset: canary\n      weight: 10</code></pre><blockquote>\n<p><strong>Note:</strong> This example statically defines the weights for each stage. You can reconfigure the pipeline as code to dynamically calculate and increase the <code>ServiceSplitter</code> weights. Check out the documentation on <a href=\"https://spinnaker.io/guides/user/pipeline/pipeline-templates/create/\">Spinnaker pipeline templates</a> and <a href=\"https://spinnaker.io/reference/artifacts/in-kubernetes-v2/#binding-artifacts-in-manifests\">binding artifacts in Kubernetes manifests</a>.</p>\n</blockquote>\n<p>If you review the configuration in the Consul UI, the configuration reflects that 90% of traffic goes to the baseline version and 10% goes to canary:</p><img src=\"https://www.datocms-assets.com/2885/1619026018-consuluiservicesplitter.png\" /><p>Each time the pipeline passes a canary analysis, it updates Consul’s service splitter to increase traffic to the canary version by 20%. For example, if the canary analysis succeeds with 30% of requests going to the canary version, Spinnaker changes the text manifest for the service splitter to 50%:</p><pre><code>apiVersion: consul.hashicorp.com/v1alpha1\nkind: ServiceSplitter\nmetadata:\n  name: web\nspec:\n  splits:\n    - serviceSubset: baseline\n      weight: 50\n    - serviceSubset: canary\n      weight: 50</code></pre><img src=\"https://www.datocms-assets.com/2885/1619026093-consulcanarysplitter.png\" /><p>You can configure Spinnaker canary analysis with a variety of parameters. “Lifetime” determines how long the stage will run, “Delay” sets aside time for the requests to warm up, and “Interval” provides a time window for Kayenta to run statistical analysis. In this demonstration example, the canary analysis runs once for three minutes. In your environment, choose the “Lifetime” based on your canary metrics, time for evaluation, and volume of requests.</p><img src=\"https://www.datocms-assets.com/2885/1619026142-consulspinnakercanaryanalysis.png\" /><h2><a href=\"#automated-canary-deployment\">»</a><a></a>Automated Canary Deployment</h2>\n<p>You can now start a canary deployment for version 2 of “web”. For this example, use the load testing tool <a href=\"https://k6.io/docs/getting-started/running-k6\">k6</a> to generate some user requests to the “ui” service. Run the <a href=\"https://github.com/joatmon08/spinnaker-consul/blob/main/k6/script.js\">script</a> located in the example repository. User requests will generate the data points for Spinnaker’s automated canary analysis:</p><pre><code>$ k6 run -e UI_ENDPOINT= k6/script.js --duration 60m</code></pre><p>As the pipeline runs, the “web” service continues to respond to user requests. Each request generates data in Prometheus. As the pipeline progresses, it continuously analyzes the user traffic in Prometheus:</p><img src=\"https://www.datocms-assets.com/2885/1619026276-consulcanarysuccess.png\" /><p>After the pipeline passes the 100% canary analysis stage, Spinnaker replaces the baseline release with the canary version. The “Release” stage applies a copy of the canary Kubernetes manifest but includes a tag for “baseline” release. The stage also resets Consul’s <code>ServiceSplitter</code> to default 100% of traffic to the baseline version:</p><pre><code>apiVersion: consul.hashicorp.com/v1alpha1\nkind: ServiceSplitter\nmetadata:\n  name: web\nspec:\n  splits:\n    - serviceSubset: baseline\n      weight: 100\n    - serviceSubset: canary\n      weight: 0</code></pre><p>Finally, the pipeline deletes the canary version of the “web” service:</p><img src=\"https://www.datocms-assets.com/2885/1619026354-consulcanarydelete.png\" /><p>You can examine the effect of the pipeline on the “web” service. The Grafana dashboard shows zero errors in the canary version while running the pipeline. Traffic to the canary increases as the pipeline progresses and canary analyses pass. When the pipeline completes, the new baseline version serves all user requests:</p><img src=\"https://www.datocms-assets.com/2885/1619026427-consulgrafanasuccess.png\" /><p>However, what happens when the canary version has a bug? The bug causes no errors at 10% canary traffic. As the pipeline increases the traffic split in Consul to 30% and more users access the service, the bug appears to cause some user errors:</p><img src=\"https://www.datocms-assets.com/2885/1619026470-consulgrafanafail.png\" /><p>When the pipeline analyzes the canary at 30%, it recognizes the increased error rate. It rolls back the canary by resetting 100% of traffic to the baseline version. You can still use the canary version of the application to debug the error in isolation since it does not receive traffic:</p><img src=\"https://www.datocms-assets.com/2885/1619026515-consulspinnakerfail.png\" /><h2><a href=\"#conclusion\">»</a><a></a>Conclusion</h2>\n<p>By adding Consul service mesh’s observability and traffic management to your continuous delivery pipelines, you can implement a side-by-side canary deployment. To further automate the process, you can use Spinnaker’s automated canary analysis to determine when to increase traffic to the new version of your application or system. Automated canary deployment reduces the manual evaluation of metrics and ensures your application’s availability with automated rollback. With the ability to configure Consul outside Kubernetes, you can apply this pattern to any service on any platform, as long as you’ve registered the canary application with the service mesh.</p>\n<p>For additional information on configuring Consul for observability, review <a href=\"https://learn.hashicorp.com/tutorials/consul/kubernetes-layer7-observability\">our tutorial</a> on Learn. Spinnaker can also use metrics collected from <a href=\"https://spinnaker.io/reference/halyard/commands/#hal-config-canary\">other systems</a>, such as Datadog. Check out our blog post on <a href=\"https://www.hashicorp.com/blog/leveling-up-service-mesh-with-observability-distributed-tracing-for-consul\">how to use Consul with other metrics systems</a>. To implement automated canary analysis with native Kubernetes tooling, review <a href=\"https://github.com/nicholasjackson/consul-canary-deployment\">this example of automated canary deployment using Flagger</a>.</p>\n<p><em>Questions about this post? Add them to the <a href=\"https://discuss.hashicorp.com/t/blog-automated-canary-deployment-with-hashicorp-consul-and-spinnaker/23437\">community forum</a>!</em></p>","author":"Rosemary Wang","siteTitle":"HashiCorp Blog","siteHash":"219aa6310b3388f2335eba49871f4df9581f2c58eaeb5e498363b54e835b7001","entryHash":"0cf3aa5d9c50028913c62b878183329e3052ac3cb11134e53996ee7de711bf65","category":"Tech"}
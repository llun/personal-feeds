{"title":"Amazon Redshift ML Is Now Generally Available – Use SQL to Create Machine Learning Models and Make Predictions from Your Data","link":"https://aws.amazon.com/blogs/aws/amazon-redshift-ml-is-now-generally-available-use-sql-to-create-machine-learning-models-and-make-predictions-from-your-data/","date":1622145610000,"content":"<p>With <a href=\"https://aws.amazon.com/redshift/\">Amazon Redshift</a>, you can use SQL to query and combine exabytes of structured and <a href=\"https://aws.amazon.com/blogs/big-data/amazon-redshift-announces-general-availability-of-support-for-json-and-semi-structured-data-processing/\">semi-structured</a> data across your data warehouse, <a href=\"https://aws.amazon.com/blogs/aws/new-for-amazon-redshift-data-lake-export-and-federated-queries/\">operational databases</a>, and <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/c-using-spectrum.html\">data lake</a>. Now that <a href=\"https://aws.amazon.com/blogs/aws/new-aqua-advanced-query-accelerator-for-amazon-redshift/\">AQUA (Advanced Query Accelerator) is generally available</a>, you can improve the performance of your queries by up to 10 times with no additional costs and no code changes. In fact, Amazon Redshift provides <a href=\"https://aws.amazon.com/blogs/big-data/get-up-to-3x-better-price-performance-with-amazon-redshift-than-other-cloud-data-warehouses/\">up to three times better price/performance</a> than other cloud data warehouses.</p> \n<p>But what if you want to go a step further and process this data to train <strong>machine learning</strong> (ML) models and use these models to generate insights from data in your warehouse? For example, to implement use cases such as forecasting revenue, predicting customer churn, and detecting anomalies? In the past, you would need to export the training data from Amazon Redshift to an <a href=\"https://aws.amazon.com/s3/\">Amazon Simple Storage Service (Amazon S3)</a> bucket, and then configure and start a machine learning training process (for example, using <a href=\"https://aws.amazon.com/sagemaker/\">Amazon SageMaker</a>). This process required many different skills and usually more than one person to complete. Can we make it easier?</p> \n<p>Today, <a href=\"https://aws.amazon.com/redshift/features/redshiftML/\">Amazon Redshift ML</a> is <strong>generally available</strong> to help you create, train, and deploy machine learning models directly from your Amazon Redshift cluster. To create a machine learning model, you use a simple SQL query to specify the data you want to use to train your model, and the output value you want to predict. For example, to create a <strong>model</strong> that predicts the success rate for your marketing activities, you define your <strong>inputs</strong> by selecting the columns (in one or more tables) that include customer profiles and results from previous marketing campaigns, and the <strong>output</strong> column you want to predict. In this example, the output column could be one that shows whether a customer has shown interest in a campaign.</p> \n<p>After you run the SQL command to create the model, Redshift ML securely exports the specified data from Amazon Redshift to your S3 bucket and calls <a href=\"https://aws.amazon.com/sagemaker/\">Amazon SageMaker Autopilot</a> to prepare the data (pre-processing and feature engineering), select the appropriate pre-built algorithm, and apply the algorithm for model training. You can optionally specify the algorithm to use, for example <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html\">XGBoost</a>.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/04/redshift-ml-create-model.png\"><img src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/05/04/redshift-ml-create-model-1024x416.png\" /></a></p> \n<p>Redshift ML handles all of the interactions between Amazon Redshift, S3, and SageMaker, including all the steps involved in training and compilation. When the model has been trained, Redshift ML uses <a href=\"https://aws.amazon.com/sagemaker/neo/\">Amazon SageMaker Neo</a> to optimize the model for deployment and makes it available as a SQL <strong>function</strong>. You can use the SQL function to apply the machine learning model to your data in queries, reports, and dashboards.</p> \n<p>Redshift ML now includes many new features that were not available during the preview, including <a href=\"https://aws.amazon.com/vpc/\">Amazon Virtual Private Cloud (VPC)</a> support. For example:</p> \n<ul> \n <li>You can now <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/r_CREATE_MODEL.html#r_byom_create_model\">import a SageMaker model</a> into your Amazon Redshift cluster (<strong>local inference</strong>).</li> \n</ul> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/04/29/redshift-ml-import-model-local-inference.png\"><img src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/04/29/redshift-ml-import-model-local-inference-1024x406.png\" /></a></p> \n<ul> \n <li>You can also create SQL functions that use existing SageMaker <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-deployment.html\">endpoints</a> to make predictions (<strong>remote inference</strong>). In this case, Redshift ML is batching calls to the endpoint to speed up processing.</li> \n</ul> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/04/29/redshift-ml-import-model-remote-inference.png.png\"><img src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/04/29/redshift-ml-import-model-remote-inference.png-1024x316.png\" /></a></p> \n<p>Before looking into how to use these new capabilities in practice, let’s see the difference between Redshift ML and similar features in AWS databases and analytics services.</p> \n<table> \n <tbody> \n  <tr> \n   <td><strong>ML Feature</strong></td> \n   <td><b>Data</b></td> \n   <td><strong>Training<br /> from SQL</strong></td> \n   <td><strong>Predictions<br /> using SQL Functions</strong></td> \n  </tr> \n  <tr> \n   <td><a href=\"https://aws.amazon.com/redshift/features/redshiftML/\">Amazon Redshift ML</a></td> \n   <td> <p>Data warehouse</p> <p><a href=\"https://aws.amazon.com/blogs/aws/new-for-amazon-redshift-data-lake-export-and-federated-queries/\">Federated relational databases</a></p> <p>S3 data lake (with <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/c-using-spectrum.html\">Redshift Spectrum</a>)</p></td> \n   <td>Yes, using<br /> Amazon SageMaker Autopilot</td> \n   <td>Yes, a model can be imported and executed inside the Amazon Redshift cluster, or invoked using a SageMaker <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-deployment.html\">endpoint</a>.</td> \n  </tr> \n  <tr> \n   <td><a href=\"https://aws.amazon.com/rds/aurora/machine-learning/\">Amazon Aurora ML</a></td> \n   <td>Relational database<br /> (<a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-ml.html\">compatible with MySQL or PostgreSQL</a>)</td> \n   <td>No</td> \n   <td> <p>Yes, using a SageMaker <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-deployment.html\">endpoint</a>.</p> <p>A native integration with <a href=\"https://aws.amazon.com/comprehend/\">Amazon Comprehend</a> for sentiment analysis is also available.</p></td> \n  </tr> \n  <tr> \n   <td><a href=\"https://docs.aws.amazon.com/athena/latest/ug/querying-mlmodel.html\">Amazon Athena ML</a></td> \n   <td> <p>S3 data lake</p> <p>Other data sources can be used through <a href=\"https://docs.aws.amazon.com/athena/latest/ug/connect-to-a-data-source.html\">Athena Federated Query</a>.</p></td> \n   <td>No</td> \n   <td>Yes, using a SageMaker <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-deployment.html\">endpoint</a>.</td> \n  </tr> \n </tbody> \n</table> \n<p><span><strong>Building a Machine Learning Model with Redshift ML<br /> </strong></span>Let’s build a model that predicts if customers will accept or decline a marketing offer.</p> \n<p>To manage the interactions with S3 and SageMaker, Redshift ML needs permissions to access those resources. I create an <a href=\"https://aws.amazon.com/iam/\">AWS Identity and Access Management (IAM)</a> role as <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/cluster-setup.html\">described in the documentation</a>. I use <code>RedshiftML</code> for the role name. Note that the <a href=\"https://aws.amazon.com/blogs/security/how-to-use-trust-policies-with-iam-roles/\">trust policy of the role</a> allows both Amazon Redshift and SageMaker to assume the role to interact with other AWS services.</p> \n<p>From the <a href=\"https://console.aws.amazon.com/redshiftv2/home\">Amazon Redshift console</a>, I create a cluster. In the cluster permissions, I associate the <code>RedshiftML</code> IAM role. When the cluster is available, I load the same dataset used in this super interesting <a href=\"https://aws.amazon.com/blogs/aws/amazon-sagemaker-autopilot-fully-managed-automatic-machine-learning/\">blog post that my colleague Julien wrote when SageMaker Autopilot was announced</a>.</p> \n<p>The file I am using (<code>bank-additional-full.csv</code>) is in <a href=\"https://en.wikipedia.org/wiki/Comma-separated_values\">CSV</a> format. Each line describes a direct marketing activity with a customer. The last column (<code>y</code>) describes the outcome of the activity (if the customer subscribed to a service that was marketed to them).</p> \n<p>Here are the first few lines of the file. The first line contains the headers.</p> \n<div> \n <pre><code><strong>age,job,marital,education,default,housing,loan,contact,month,day_of_week,duration,campaign,pdays,previous,poutcome,emp.var.rate,cons.price.idx,cons.conf.idx,euribor3m,nr.employed,y </strong>56,housemaid,married,basic.4y,no,no,no,telephone,may,mon,261,1,999,0,nonexistent,1.1,93.994,-36.4,4.857,5191.0,no\n57,services,married,high.school,unknown,no,no,telephone,may,mon,149,1,999,0,nonexistent,1.1,93.994,-36.4,4.857,5191.0,no\n37,services,married,high.school,no,yes,no,telephone,may,mon,226,1,999,0,nonexistent,1.1,93.994,-36.4,4.857,5191.0,no\n40,admin.,married,basic.6y,no,no,no,telephone,may,mon,151,1,999,0,nonexistent,1.1,93.994,-36.4,4.857,5191.0,no</code></pre> \n</div> \n<p>I store the file in one of my S3 buckets. The S3 bucket is used to unload data and store SageMaker training artifacts.</p> \n<p>Then, using the <a href=\"https://docs.aws.amazon.com/redshift/latest/mgmt/query-editor.html\">Amazon Redshift query editor</a> in the console, I create a table to load the data.</p> \n<pre><code>CREATE TABLE direct_marketing (\n\tage DECIMAL NOT NULL, \n\tjob VARCHAR NOT NULL, \n\tmarital VARCHAR NOT NULL, \n\teducation VARCHAR NOT NULL, \n\tcredit_default VARCHAR NOT NULL, \n\thousing VARCHAR NOT NULL, \n\tloan VARCHAR NOT NULL, \n\tcontact VARCHAR NOT NULL, \n\tmonth VARCHAR NOT NULL, \n\tday_of_week VARCHAR NOT NULL, \n\tduration DECIMAL NOT NULL, \n\tcampaign DECIMAL NOT NULL, \n\tpdays DECIMAL NOT NULL, \n\tprevious DECIMAL NOT NULL, \n\tpoutcome VARCHAR NOT NULL, \n\temp_var_rate DECIMAL NOT NULL, \n\tcons_price_idx DECIMAL NOT NULL, \n\tcons_conf_idx DECIMAL NOT NULL, \n\teuribor3m DECIMAL NOT NULL, \n\tnr_employed DECIMAL NOT NULL, \n\ty BOOLEAN NOT NULL\n);</code></pre> \n<p>I load the data into the table using the <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/r_COPY.html\">COPY command</a>. I can use the same IAM role I created earlier (<code>RedshiftML</code>) because I am using the same S3 bucket to import and export the data.</p> \n<div> \n <pre><code>COPY direct_marketing \nFROM 's3://my-bucket/direct_marketing/bank-additional-full.csv' \nDELIMITER ',' IGNOREHEADER 1\nIAM_ROLE 'arn:aws:iam::123412341234:role/RedshiftML'\nREGION 'us-east-1';</code></pre> \n</div> \n<p>Now, I create the model straight form the SQL interface using the new <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/r_CREATE_MODEL.html\">CREATE MODEL statement</a>:</p> \n<pre><code>CREATE MODEL direct_marketing\nFROM direct_marketing\nTARGET y\nFUNCTION predict_direct_marketing\nIAM_ROLE 'arn:aws:iam::123412341234:role/RedshiftML'\nSETTINGS (\n  S3_BUCKET 'my-bucket'\n);</code></pre> \n<p>In this SQL command, I specify the parameters required to create the model:</p> \n<ul> \n <li><code>FROM</code> – I select all the rows in the <code>direct_marketing</code> table, but I can replace the name of the table with a nested query (see example below).</li> \n <li><code>TARGET</code> – This is the column that I want to predict (in this case, <code>y</code>).</li> \n <li><code> FUNCTION</code> – The name of the SQL function to make predictions.</li> \n <li><code>IAM_ROLE</code> – The <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/cluster-setup.html\">IAM role assumed by Amazon Redshift and SageMaker</a> to create, train, and deploy the model.</li> \n <li><code>S3_BUCKET</code> – The S3 bucket where the training data is temporarily stored, and where model artifacts are stored if you choose to retain a copy of them.</li> \n</ul> \n<p>Here I am using a <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/r_CREATE_MODEL.html#r_simple_create_model\">simple syntax</a> for the CREATE MODEL statement. For more advanced users, <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/r_CREATE_MODEL.html#r_user_guidance_create_model\">other options are available</a>, such as:</p> \n<ul> \n <li><code>MODEL_TYPE</code> – To use a specific model type for training, such as <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html\">XGBoost</a> or multilayer perceptron (MLP). If I don’t specify this parameter, SageMaker Autopilot selects the appropriate model class to use.</li> \n <li><code>PROBLEM_TYPE</code> – To define the type of problem to solve: regression, binary classification, or multiclass classification. If I don’t specify this parameter, the problem type is discovered during training, based on my data.</li> \n <li><code>OBJECTIVE</code> – The objective metric used to measure the quality of the model. This metric is optimized during training to provide the best estimate from data. If I don’t specify a metric, the default behavior is to use <a href=\"https://en.wikipedia.org/wiki/Mean_squared_error\">mean squared error (MSE)</a> for regression, the <a href=\"https://en.wikipedia.org/wiki/F-score\">F1 score</a> for binary classification, and accuracy for multiclass classification. Other available options are F1Macro (to apply F1 scoring to multiclass classification) and <a href=\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve\">area under the curve (AUC)</a>. More information on <a href=\"https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_AutoMLJobObjective.html\">objective metrics is available in the SageMaker documentation</a>.</li> \n</ul> \n<p>Depending on the complexity of the model and the amount of data, it can take some time for the model to be available. I use the <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/r_SHOW_MODEL.html\">SHOW MODEL</a> command to see when it is available:</p> \n<div> \n <pre><code>SHOW MODEL direct_marketing</code></pre> \n</div> \n<p>When I execute this command using the query editor in the console, I get the following output:</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/04/27/redshift-ml-show-model.png\"><img src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/04/27/redshift-ml-show-model-1024x730.png\" /></a></p> \n<p>As expected, the model is currently in the <code>TRAINING</code> state.</p> \n<p>When I created this model, I selected all the columns in the table as input parameters. I wonder what happens if I create a model that uses fewer input parameters? I am in the cloud and I am not slowed down by limited resources, so I create another model using a subset of the columns in the table:</p> \n<pre><code>CREATE MODEL simple_direct_marketing\nFROM (\n        SELECT age, job, marital, education, housing, contact, month, day_of_week, y\n \t  FROM direct_marketing\n)\nTARGET y\nFUNCTION predict_simple_direct_marketing\nIAM_ROLE 'arn:aws:iam::123412341234:role/RedshiftML'\nSETTINGS (\n  S3_BUCKET 'my-bucket'\n);</code></pre> \n<p>After some time, my first model is ready, and I get this output from SHOW MODEL. The actual output in the console is in multiple pages, I merged the results here to make it easier to follow:</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/04/27/redshift-ml-show-model-ready-1.png\"><img src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/04/27/redshift-ml-show-model-ready-1-989x1024.png\" /></a></p> \n<p>From the output, I see that the model has been correctly recognized as <code>BinaryClassification</code>, and <code>F1</code> has been selected as the objective. The <a href=\"https://en.wikipedia.org/wiki/F-score\">F1 score</a> is a metrics that considers both <a href=\"https://en.wikipedia.org/wiki/Precision_and_recall\">precision and recall</a>. It returns a value between 1 (perfect precision and recall) and 0 (lowest possible score). The final score for the model (<code>validation:f1</code>) is 0.79. In this table I also find the name of the SQL function (<code>predict_direct_marketing</code>) that has been created for the model, its parameters and their types, and an estimation of the training costs.</p> \n<p>When the second model is ready, I compare the F1 scores. The F1 score of the second model is lower (0.66) than the first one. However, with fewer parameters the SQL function is easier to apply to new data. As is often the case with machine learning, I have to find the right balance between complexity and usability.</p> \n<p><span><strong>Using Redshift ML to Make Predictions<br /> </strong></span>Now that the two models are ready, I can make predictions using SQL functions. Using the first model, I check how many false positives (wrong positive predictions) and false negatives (wrong negative predictions) I get when applying the model on the same data used for training:</p> \n<pre><code>SELECT predict_direct_marketing, y, COUNT(*)\n  FROM (SELECT predict_direct_marketing(\n                   age, job, marital, education, credit_default, housing,\n                   loan, contact, month, day_of_week, duration, campaign,\n                   pdays, previous, poutcome, emp_var_rate, cons_price_idx,\n                   cons_conf_idx, euribor3m, nr_employed), y\n          FROM direct_marketing)\n GROUP BY predict_direct_marketing, y;</code></pre> \n<p>The result of the query shows that the model is better at predicting negative rather than positive outcomes. In fact, even if the number of true negatives is much bigger than true positives, there are much more false positives than false negatives. I added some comments in green and red to the following screenshot to clarify the meaning of the results.</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/04/28/redshift-ml-query-check.png\"><img src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/04/28/redshift-ml-query-check-1024x496.png\" /></a></p> \n<p>Using the second model, I see how many customers might be interested in a marketing campaign. Ideally, I should run this query on new customer data, not the same data I used for training.</p> \n<pre><code>SELECT COUNT(*)\n  FROM direct_marketing\n WHERE predict_simple_direct_marketing(\n           age, job, marital, education, housing,\n           contact, month, day_of_week) = true;</code></pre> \n<p>Wow, looking at the results, there are more than 7,000 prospects!</p> \n<p><a href=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/04/29/redshift-ml-query-prospects.png\"><img src=\"https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2021/04/29/redshift-ml-query-prospects-1024x316.png\" /></a></p> \n<p><span><strong>Availability and Pricing<br /> </strong></span><a href=\"https://aws.amazon.com/redshift/features/redshiftML/\">Redshift ML</a> is available today in the following <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regions_az/\">AWS Regions</a>: US East (Ohio), US East (N Virginia), US West (Oregon), US West (San Francisco), Canada (Central), Europe (Frankfurt), Europe (Ireland), Europe (Paris), Europe (Stockholm), Asia Pacific (Hong Kong) Asia Pacific (Tokyo), Asia Pacific (Singapore), Asia Pacific (Sydney), and South America (São Paulo). For more information, see the <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\">AWS Regional Services list</a>.</p> \n<p>With Redshift ML, you pay only for what you use. When training a new model, you pay for the <a href=\"https://aws.amazon.com/sagemaker/\">Amazon SageMaker Autopilot</a> and <a href=\"https://aws.amazon.com/s3/\">S3</a> resources used by Redshift ML. When making predictions, there is no additional cost for models imported into your Amazon Redshift cluster, as in the example I used in this post.</p> \n<p>Redshift ML also allows you to use existing <a href=\"https://aws.amazon.com/sagemaker/\">Amazon SageMaker</a> endpoints for inference. In that case, the usual <a href=\"https://aws.amazon.com/sagemaker/pricing/\">SageMaker pricing</a> for real-time inference applies. Here you can find a <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/cost.html\">few tips on how to control your costs with Redshift ML</a>.</p> \n<p>To learn more, you can see <a href=\"https://aws.amazon.com/blogs/big-data/create-train-and-deploy-machine-learning-models-in-amazon-redshift-using-sql-with-amazon-redshift-ml/\">this blog post from when Redshift ML was announced in preview</a> and the <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/machine_learning.html\">documentation</a>.</p> \n<p><a href=\"https://aws.amazon.com/redshift/features/redshiftML/\"><strong>Start getting better insights from your data with Redshift ML.</strong></a></p> \n<p>— <a href=\"https://twitter.com/danilop\">Danilo</a></p>","author":"Danilo Poccia","siteTitle":"AWS News Blog","siteHash":"6093e072e4117ec22616e844cb857d03ca62c57a411a8affc77cb5e8b6b15bf6","entryHash":"4ef0cb7ea441c28ed57d30962bb6d7922448631aea6f37edb090b93b2daea2c2","category":"Tech"}
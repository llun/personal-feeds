{"title":"Wall of Text #13: CGI","link":"https://blog.whs.in.th/node/3476","date":1594663593000,"content":"<p>น้อง Intern บอกว่ากำลังหัดเขียน Web server อยู่ เลยสงสัยว่าแล้วจะทำให้ Web server รันโปรแกรมที่เป็น dynamic ได้ไง (สมมุติว่า Python)</p>\n\n\n\n<p>เรื่องที่น่าแปลกใจคือคนรุ่นใหม่เหมือนจะไม่มีประสบการณ์ใช้งาน PHP กันแล้ว เข้าใจว่าบางมหาวิทยาลัยนอกเหนือจาก Top 5 อาจจะยังมีการสอนอยู่บ้าง ตอนที่โชว์ให้ดูว่า PHP มันวางไฟล์แล้วใช้ได้เลยนี่มันเลยดูเท่มาก เพราะถ้าเขียนภาษาอื่นๆ อย่างน้อยก็ต้อง restart app server</p>\n\n\n\n<h2>CGI</h2>\n\n\n\n<p>ในสมัยโบราณ WWW มีแต่หน้าเว็บ static ต่อมาเราอยากให้หน้าเว็บมีการอัพเดตบ้าง เลยมีผู้ที่ออกแบบมาตรฐาน CGI ขึ้นมาเพื่อให้ Web server สามารถเรียกโปรแกรมอื่นได้</p>\n\n\n\n<p>การทำงานของ CGI ก็ง่ายมาก คือเรากำหนดว่าที่ URL นี้แทนที่จะส่งไฟล์กลับไปให้ ให้เรียกโปรแกรมที่กำหนดให้ ที่นิยมกันก็คือจะกำหนดเป็น folder /cgi-bin ไปเลย</p>\n\n\n\n<p>เมื่อเราเข้า URL ที่อยู่ใน cgi-bin แล้ว Web server จะไปเรียกโปรแกรมนั้นๆ โดยส่ง Header ไปทาง Environment variable และส่ง Request body ไปเป็น input ของโปรแกรม จากนั้นโปรแกรมจะ print สิ่งที่ต้องการให้แสดงบนหน้าเว็บออกมา ถ้าต้องการเซต Header มาด้วยก็ให้ print ก่อนเนื้อหาได้</p>\n\n\n\n<p>วิธีนี้ค่อนข้างนิยมในสมัยก่อน ภาษาที่ใช้เขียนก็ได้ทุกภาษาขอให้เรียกเป็นโปรแกรมได้เท่านั้น เช่น C, Perl, PHP ก็ใช้ได้ทั้งหมด</p>\n\n\n\n<p>ยกตัวอย่างเช่น <a href=\"http://macroart.net/2013/06/how-difficult-to-develop-forum-with-million-visitors-per-day/\">Pantip ในยุคแรกใช้ภาษา Perl ในการพัฒนา</a> ในหน้ากระทู้นั้นจะเป็น HTML ธรรมดาๆ เมื่อมีการโพสต์ comment ก็จะไปเรียก Perl script เข้าไปแก้ไขไฟล์ HTML (ซึ่งปัญหาที่ตามมาคือเมื่อ concurrent มากๆ แล้ว Script อาจจะแย่งกันเขียนทำให้ไฟล์พัง)</p>\n\n\n\n<h2>PHP SAPI</h2>\n\n\n\n<p>ปัญหาของ CGI คือทุกครั้งที่มีการเรียก CGI Script จะต้องเรียก process ย่อยๆ นั้นใหม่ ซึ่งถ้าเขียนด้วย C ก็ไม่มีปัญหาเท่าไร แต่บางภาษาอาจจะ start ช้ามากๆ เช่นสมัยก่อนผมเคยใช้ Python แล้วเซตไม่ถูกเลยไปใช้ CGI ก็เสียเวลา start python ทุก request เกือบ 2 วินาที</p>\n\n\n\n<p>มันก็มีคนแก้ไขปัญหานี้หลายๆ ทาง อันหนึ่งคือก็เอา PHP ไปฝังไว้กับ Web server เลย โดย PHP จะมีส่วนที่เรียกว่า SAPI (Server API) ซึ่งเป็น library ที่เข้าไป integrate กับ web server (เช่น Apache) ให้เมื่อมีการเรียกหน้าที่กำหนดแล้วจะไปเรียก PHP API ที่สั่งให้ script ทำงาน</p>\n\n\n\n<p>วิธีนี้ทำให้ไม่ต้อง start PHP ใหม่ทุก process เพราะ PHP จะอยู่กับ web server ไปเลย</p>\n\n\n\n<p>ข้อเสียหลักๆ ของการทำแบบนี้คือ</p>\n\n\n\n<ol><li>PHP library ไม่ได้พัฒนาให้ thread safe ดังนั้นจะใช้ Apache ได้แค่ใน mode prefork (แยก process แทน thread) ซึ่งเปลือง memory กว่า</li><li>Code จะถูกรันด้วยสิทธิ์ของ web server ซึ่งในกรณีที่ใช้ share hosting แล้วจะทำให้เราสามารถเข้าไปอ่าน/แก้ไขไฟล์ของ user อื่นๆ บนเครื่องได้ทุกคน</li><li>รัน PHP ได้แค่ version เดียวต่อ web server (ในกรณีที่มี legacy code ที่อัพเวอร์ชั่นไม่ได้)</li></ol>\n\n\n\n<p>ถึงใน PHP จะมีข้อจำกัดเยอะ แต่ในช่วงประมาณปี 2008 ที่คนเริ่มสนใจ Python/Ruby ทั้งสองภาษาก็ยัง deploy ด้วยท่านี้ได้ด้วย mod_wsgi หรือ Phusion Passenger</p>\n\n\n\n<h2>FastCGI</h2>\n\n\n\n<p>ท่าที่ค่อนข้างเวิร์คกว่าในการ Deploy web application คือ FastCGI ซึ่งเป็น standard อีกตัวหนึ่งที่เข้ามาแทน CGI</p>\n\n\n\n<p>การทำงานของ FastCGI คือให้ web application นั้นเปิด socket ไว้ (อาจจะเป็น UNIX socket หรือ TCP ก็ได้) แล้ว Web server จะส่งต่อ request เข้ามาใน socket และเอาผลลัพท์กลับไปแสดง</p>\n\n\n\n<p>วิธีนี้ทำให้เราสามารถ scale application server / web server แยกกันต่างหากได้ และรันเป็นคนละ user เพื่อความปลอดภัยได้</p>\n\n\n\n<p>ปัจจุบันท่าที่นิยมใช้ Deploy PHP บน nginx ก็จะใช้ php-fpm ซึ่งจะรับ FastCGI connection เข้ามาประมวลผลด้วย PHP และช่วยจัดการเพิ่มลด process ให้อัตโนมัติ</p>\n\n\n\n<h2>Reverse proxy</h2>\n\n\n\n<p>ถ้า FastCGI คือการที่เรารับ HTTP request แล้วแปลงเป็น FastCGI request ส่งต่อ ทำไมเราไม่ส่ง request จริงไปเลยล่ะ?</p>\n\n\n\n<p>ผมเข้าใจว่าท่า Reverse proxy เริ่มดังในช่วงหลังจากที่ Node.js เข้ามาแล้ว เพราะเป็นภาษา interpreted ภาษาแรกที่บอกว่าใช้ web server ในตัวมันรับโหลดได้เลยเพราะมันเป็น async ซึ่งเป็นจุดขายที่ว้าวมากในตอนนั้น</p>\n\n\n\n<p>หลังจาก Node.js แล้ว Go ก็เป็นอีกภาษาหนึ่งที่บอกเหมือนกันว่าให้ใช้ web server ในตัวรับโหลดได้เลย</p>\n\n\n\n<p>ความแตกต่างระหว่างการเปิด web server กับ FastCGI ที่จะเห็นได้ก็คือ</p>\n\n\n\n<ul><li>FastCGI เราเชื่อ web server ตัวหน้าทั้งหมด แต่การรันเป็น web server เราจะไม่เชื่อ web server ตัวหน้า ต้องเขียนโค้ดมาประมวลผลอีกที</li><li>เช่น web server จะมองเห็น IP คนที่ต่อเข้ามาและส่งให้ FastCGI ใน field พิเศษ แต่ถ้าเป็น reverse proxy นั้น application ต้องอ่านจาก X-Forwarded-For อีกทีหนึ่ง ซึ่งก็ต้องระวังความปลอดภัยด้วยเพราะ user ก็สามารถเซต header ได้</li><li>หรือถ้า web server ตัวหน้าใช้ HTTPS แล้วต่อเข้าด้านหลังด้วย HTTP ธรรมดาจะทำให้ application ไม่ทราบรายละเอียด connection เลยว่าเป็น HTTPS หรือไม่ (นอกจากจะเชื่อตาม header) และไม่สามารถใช้ฟีเจอร์อื่นๆ ได้เช่น Client certificate หรือ check cipher suite</li><li>Web server ของบางภาษาอาจจะรับโหลดไม่เก่งเท่า Web server จริงๆ เช่น <a href=\"https://docs.gunicorn.org/en/stable/deploy.html\">Gunicorn แนะนำให้ใช้ web server คั่นหน้าเสมอ</a> เนื่องจากถ้า client ทำงานช้า (Slowloris attack) จะเสีย thread ไปเปล่าๆ หรือโค้ดในการ serve static file ก็อาจจะไม่เก่งเท่า</li><li>Protocol HTTP นั้น parse ยากกว่า FastCGI protocol</li></ul>\n\n\n\n<h2>What comes next</h2>\n\n\n\n<p>ทั้งหมดด้านบนคือ protocol หลักๆ ที่ยังใช้อยู่ในปัจจุบัน</p>\n\n\n\n<p>แต่ในอนาคตก็เป็นไปได้ว่าอาจจะมีวิธีอื่นๆ เข้ามาก็ได้ ท่าที่เห็นในตอนนี้คือ event-driven เสียเป็นส่วนใหญ่</p>\n\n\n\n<h3>ASGI v1</h3>\n\n\n\n<p>ผมเคยอวย ASGI v1 มากๆ มันเป็นความพยายามที่จะทำให้ Django กลายเป็น async ทั้งๆ ที่มันเขียนเป็น sync มาทั้งหมด</p>\n\n\n\n<p>วิธีการคือ web server ตัวหน้า (ASGI gateway) จะแปลง HTTP request ที่เข้ามาเป็น message แล้วยิงเข้าไปใน message queue จากนั้น ASGI server จะรันตาม request ที่ได้รับแล้วส่งผลลัพท์กลับไปใน message queue เช่นกัน</p>\n\n\n\n<p>ท่านี้ผมเห็นครั้งแรกใน <a href=\"https://mongrel2.org/features/languages.html\">Mongrel2</a> ซึ่งใช้ ZeroMQ</p>\n\n\n\n<p>วิธีนี้ยังสามารถประยุกต์ใช้งานกับ protocol อื่นๆ ได้อีก ซึ่งท่าที่ทำให้มันเท่มากคือ WebSocket โดย gateway จะยิง event ต่างๆ เช่น client connected, client message เข้าไปใน message queue ทำให้โค้ด scale ได้ง่ายเนื่องจากไม่มีการ hold connection เลย (นอกจาก MQ)</p>\n\n\n\n<p>ด้วยความที่มันรันบน message queue มันทำให้การ scale ต่างๆ เหมือนการ scale message queue ทั่วไป รวมถึงว่าเราสามารถรัน gateway 1 server ที่ใช้ resource ไม่มากแล้วรัน ASGI server หลายๆ server ก็ได้</p>\n\n\n\n<p>ปัญหาที่เจอในการใช้งานจริงคือเนื่องจากมันเป็น request-response ในครั้งเดียว web server เลยจะต้องรับ connection ทั้งหมดมาก่อนแล้วค่อยถาม application ว่าเอาไหม ซึ่งจะทำให้เกิดปัญหา queue backlog ยาวและ message queue บางประเภท cancel message ไม่ได้</p>\n\n\n\n<p>อีกปัญหาหนึ่งคือถ้า user upload file ขนาดใหญ่มา เป็นปัญหาที่มันแก้ไม่ได้เลย เพราะส่งทั้งไฟล์ไปบน MQ ก็จะ overhead สูงมาก จะเขียนลงเครื่องก็อาจจะอยู่คนละเครื่อง จะเอาไปไว้ใน storage service ก็เพิ่ม dependency</p>\n\n\n\n<h3>Serverless</h3>\n\n\n\n<p>ถ้าย้อนกลับไปอ่านข้างบนจะพบว่า Serverless ที่กำลังฮิตอยู่ตอนนี้ จริงๆ มันคือ CGI กลับชาติมาเกิดเป๊ะๆ เลย แล้วปัญหาที่คนใช้ serverless เจออย่าง cold start นาน ก็คือปัญหาเดียวกับ CGI แถมมันยังรับได้แค่ 1 request per instance เหมือนกันด้วย</p>\n\n\n\n<p>จะต่างกันแค่ว่า serverless application ไม่โดนบังคับให้ออกหลังจาก serve request จบแล้วแต่จะถูก freeze ไว้แทน ทำให้ครั้งถัดไปไม่เสีย cold start อีก</p>\n\n\n\n<p>ไอเดียของ AWS Lambda ผมเข้าใจว่าเค้าน่าจะพยายามทำ code execution สำหรับ event ต่างๆ อยู่ (แบบที่ <a href=\"https://www.twilio.com/docs/runtime/functions\">Twilio มี Functions</a>) แล้วถึงพบว่ามันเอาไปรันเป็น web ได้ทีหลัง เวลาใช้ทำเว็บเลยจะเห็นว่าท่ามันยุ่งยากมาก คือต้องมี API Gateway/ALB แปลง request เป็น event เสียก่อนแล้วค่อยไป call lambda Invoke API ไม่สามารถเรียก function ตรงๆ ได้เลย (อย่างน้อยๆ ก็ต้องเรียกผ่าน Lambda API)</p>\n\n\n\n<p>ก็จะเห็นมีแต่ Google Cloud Function ที่ทำกลับกันคือมี HTTP API แล้วเพิ่มให้รองรับ event ผ่าน webhook แทน</p>","author":"whs","siteTitle":"Quietly Verbose","siteHash":"5f972a6fe70a917eb1b1aa165b3cb2be8a9465af33ab38bf05f34c55c0e40587","entryHash":"99fea36ec60edfb2d6167003263761bb22e014fcfc434d06457fe3085bb5158d","category":"Thai"}
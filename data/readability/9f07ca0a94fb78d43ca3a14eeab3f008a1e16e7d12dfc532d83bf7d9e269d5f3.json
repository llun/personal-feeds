{"title":"A new lens technology is primed to jumpstart phone cameras","link":"https://arstechnica.com/?p=1740149","date":1612612627000,"content":"<div id=\"readability-page-1\" class=\"page\"><div><h4>Say cheese —</h4><h2 itemprop=\"description\">Smartphone optics have been pretty much the same for more than a decade.</h2></div><div itemprop=\"articleBody\"><figure><img src=\"https://cdn.arstechnica.net/wp-content/uploads/2021/02/smartphone-camera-800x533.jpg\" alt=\"Close-up photograph of a smartphone's multiple camera lenses.\"><figcaption></figcaption></figure><p>The camera on the first iPhone way back in 2007 was a mere 2 megapixels. And it only had a rear camera; there wasn't even a front-facing selfie shooter. Today, you'll find multiple cameras on the front and back of phones—some of them with sensors as large as 108 megapixels, like the biggest camera on Samsung's <a href=\"https://www.wired.com/review/samsung-galaxy-s21-ultra/\">Galaxy S21 Ultra</a>.</p><p>But while the sensor size and megapixel counts of smartphone cameras have increased considerably in the past decade—not to mention improvements in <a href=\"https://www.wired.com/story/google-pixel-3-camera-features/\">computational photography software</a>—the lenses that help capture photos remain fundamentally unchanged.</p><figure><img src=\"https://cdn.arstechnica.net/wp-content/uploads/2019/02/wired-logo.png\" width=\"218\" height=\"58\"></figure><p>A new company called <a href=\"https://www.metalenz.com/\">Metalenz</a>, which emerges from stealth mode today, is looking to disrupt smartphone cameras with a single, flat lens system that utilizes a technology called optical metasurfaces. A camera built around this new lens tech can produce an image of the same if not better quality as traditional lenses, collect more light for brighter photos, and can even enable new forms of sensing in phones, all while taking up less space.</p><h2>A flat lens</h2><p>How does it work? Well, first it's important to understand how phone camera lenses work today. The imaging system on the back of your smartphone may have multiple cameras—the latest <a href=\"https://www.wired.com/gallery/iphone-buying-guide/\">iPhone 12 Pro</a> has three cameras on the back—but each camera has multiple lenses or lens elements stacked on top of each other. The main camera sensor on the aforementioned iPhone 12 Pro utilizes seven lens elements. A many-lens design like the iPhone's is superior to a single-lens setup; as light passes through each successive lens, the image gains sharpness and clarity.</p><figure><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2021/02/camera-array.jpg\" data-height=\"1067\" data-width=\"1600\" alt=\"An array of Metalenz-equipped camera modules.\"><img alt=\"An array of Metalenz-equipped camera modules.\" src=\"https://cdn.arstechnica.net/wp-content/uploads/2021/02/camera-array-640x427.jpg\" width=\"640\" height=\"427\" srcset=\"https://cdn.arstechnica.net/wp-content/uploads/2021/02/camera-array-1280x854.jpg 2x\"></a><figcaption><p><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2021/02/camera-array.jpg\" data-height=\"1067\" data-width=\"1600\">Enlarge</a> <span>/</span> An array of Metalenz-equipped camera modules.</p><p>Julian Knight</p></figcaption></figure><p>“The optics usually in smartphones nowadays consists of between four and seven lens elements,” says Oliver Schindelbeck, innovation manager at the optics manufacturer Zeiss, which is known for its high-quality lenses. “If you have a single lens element, just by physics you will have aberrations like distortion or dispersion in the image.”</p><p>More lenses allow manufacturers to compensate for irregularities like chromatic aberration (when colors appear on the fringes of an image) and lens distortion (when straight lines appear curved in a photo). However, stacking multiple lens elements on top of each other requires more vertical space inside the camera module. It's one of many reasons why the camera “bump” on smartphones has grown larger and larger over the years.</p><p>“The more lens elements you want to pack in a camera, the more space it needs,” Schindelbeck says. Other reasons for the size of the bump include larger image sensors and more cameras with zoom lenses, which need extra room.</p><p>Phone makers like Apple have increased the number of lens elements over time, and while some, <a href=\"https://www.wired.com/story/samsung-galaxy-s21-deals/\">like Samsung</a>, are now folding optics to create “periscope” lenses for greater zoom capabilities, companies have generally stuck with the tried-and-true stacked lens element system.</p><p>“The optics became more sophisticated, you added more lens elements, you created strong aspheric elements to achieve the necessary reduction in space, but there was no revolution in the past 10 years in this field,” Schindelbeck says.</p><h2>Introducing Metalenz</h2><p>This is where Metalenz comes in. Instead of using plastic and glass lens elements stacked over an image sensor, Metalenz's design uses a single lens built on a glass wafer that is between 1x1 to 3x3 millimeter in size. Look very closely under a microscope and you'll see nanostructures measuring one-thousandth the width of a human hair. Those nanostructures bend light rays in a way that corrects for many of the shortcomings of single-lens camera systems.</p><p>The core technology was formed through a decade of research when co-founder and CEO Robert Devlin was working on his Ph.D. at Harvard University with acclaimed physicist and Metalenz co-founder Federico Capasso. The company was spun out of the research group in 2017.</p><p>Light passes through these patterned nanostructures, which look like millions of circles with differing diameters at the microscopic level. “Much in the way that a curved lens speeds up and slows down light to bend it, each one of these allows us to do the same thing, so we can bend and shape light just by changing the diameters of these circles,” Devlin says.</p><figure><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2021/02/more-lenses.jpg\" data-height=\"1067\" data-width=\"1600\"><img src=\"https://cdn.arstechnica.net/wp-content/uploads/2021/02/more-lenses-640x427.jpg\" width=\"640\" height=\"427\" srcset=\"https://cdn.arstechnica.net/wp-content/uploads/2021/02/more-lenses-1280x854.jpg 2x\"></a><figcaption><p>Julian Knight</p></figcaption></figure><p>The resulting image quality is just as sharp as what you'd get from a multilens system, and the nanostructures do the job of reducing or eliminating many of the image-degrading aberrations common to traditional cameras. And the design doesn't just conserve space. Devlin says a Metalenz camera can deliver more light back to the image sensor, allowing for brighter and sharper images than what you'd get with traditional lens elements.</p><p>Another benefit? The company has formed partnerships with two semiconductor leaders (that can currently produce a million Metalenz \"chips\" a day), meaning the optics are made in the same foundries that manufacture consumer and industrial devices—an important step in simplifying the supply chain.</p><h2>New forms of sensing</h2><p>Metalenz will go into mass production toward the end of the year. Its first application will be to serve as the lens system of a 3D sensor in a smartphone. (The company did not give the name of the phone maker.)</p><p>Devlin says current 3D sensors, like Apple's TrueDepth camera for Face ID, actively illuminate a scene with lasers to scan faces, but this can be a drain on a phone's battery life. Since Metalenz can bring in more light to the image sensor, he claims it can help conserve power.</p><p>Other good news? If it's a 3D sensor on the front of a phone for face authentication, Devlin says the Metalenz system can eliminate the need for a bulky camera notch jutting into the screen, like the one in current iPhones. The amount of space saved by forgoing traditional lens elements will enable more phone makers to put sensors and cameras beneath a device's glass display, something we'll see <a href=\"https://www.wired.com/story/future-of-phone-design-ces-2021/\">more of this year.</a></p><p>Devlin says the applications for Metalenz reach beyond smartphones. The technology can be used in everything from instruments for health care to augmented- and virtual-reality cameras, to the cameras in automobiles.</p><p>Take spectroscopy as an example. A spectrometer is used to finely detect different wavelengths of light, and it's commonly employed in medical assays to identify particular molecules in the blood. As metasurfaces allow you to collapse “a tabletop of optics into a single surface,” Devlin claims you can pop the right sensors in a smartphone with Metalenz to do the same kind of work.</p><p>“You can actually look at the chemical signature of fruit with a spectrometer and tell whether it's ripe,” Devlin says. “It's really not just an image anymore, you're actually accessing all sorts of different forms of sense, and seeing and interacting with the world, getting a whole new set of information into the cellphone.”</p><p><em>This story originally appeared on <a href=\"https://www.wired.com/story/metalenz-smartphone-lens/\">wired.com</a>.</em></p></div></div>","author":"WIRED","siteTitle":"Ars Technica","siteHash":"5b0ddf6e8923e49262a7894cfd77962733e43fbcc565a103b48373820b310636","entryHash":"9f07ca0a94fb78d43ca3a14eeab3f008a1e16e7d12dfc532d83bf7d9e269d5f3","category":"Tech"}
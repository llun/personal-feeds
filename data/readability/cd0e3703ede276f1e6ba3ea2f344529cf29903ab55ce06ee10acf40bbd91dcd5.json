{"title":"MediaRecorder API","link":"https://webkit.org/blog/11353/mediarecorder-api/","date":1606154441000,"content":"<div id=\"readability-page-1\" class=\"page\"><article id=\"post-11353\"><div><p>Safari Technology Preview 105 and Safari in the latest iOS 14.3 beta enabled support for the MediaRecorder API by default. This API takes as input live audio/video content to produce compressed media. While the immediate use case is to record from the camera and/or microphone, this API can take any MediaStreamTrack as input, be it a capture track, coming from the network using WebRTC, or generated from HTML (Canvas, WebAudio), as illustrated in the chart below.</p><figure><img loading=\"lazy\" src=\"https://webkit.org/wp-content/uploads/image-2.png\" alt=\"\" width=\"2000\" height=\"1269\" srcset=\"https://webkit.org/wp-content/uploads/image-2.png 2000w, https://webkit.org/wp-content/uploads/image-2-300x190.png 300w, https://webkit.org/wp-content/uploads/image-2-1024x650.png 1024w, https://webkit.org/wp-content/uploads/image-2-768x487.png 768w, https://webkit.org/wp-content/uploads/image-2-1536x975.png 1536w\" sizes=\"(max-width: 2000px) 100vw, 2000px\"></figure><p>The generated output, exposed as blobs, can be readily rendered in a video element to preview the content, edit it, and/or upload to servers for sharing with others.</p><p>This API can be feature-detected, as can the set of supported file/container formats and audio/video codecs. Safari currently supports the MP4 file format with H.264 as video codec and AAC as audio codec. MediaRecorder support can be checked as follows:</p><pre><code><span>function</span> <span>supportsRecording</span>(<span>mimeType</span>)\n{\n    <span>if</span> (<span>!</span><span>window</span>.<span>MediaRecorder</span>)\n        <span>return</span> <span>false</span>;\n    <span>if</span> (<span>!</span><span>MediaRecorder</span>.<span>isTypeSupported</span>)\n        <span>return</span> <span>mimeType</span>.<span>startsWith</span>(<span>\"audio/mp4\"</span>) <span>|</span><span>|</span> <span>mimeType</span>.<span>startsWith</span>(<span>\"video/mp4\"</span>);\n    <span>return</span> <span>MediaRecorder</span>.<span>isTypeSupported</span>(<span>mimeType</span>);\n}\n</code></pre><p>The following example shows how camera and microphone can be recorded as mp4 content and locally previewed on the same page.</p><pre><code><span>&lt;<span>html</span>&gt;</span>\n<span>&lt;<span>body</span>&gt;</span>\n<span>&lt;<span>button</span> <span>onclick</span>=<span>\"startRecording()\"</span>&gt;</span>start<span>&lt;/<span>button</span>&gt;</span><span>&lt;<span>br</span>&gt;</span>\n<span>&lt;<span>button</span> <span>onclick</span>=<span>\"endRecording()\"</span>&gt;</span>end<span>&lt;/<span>button</span>&gt;</span>\n<span>&lt;<span>video</span> <span>id</span>=<span>\"video\"</span> <span>autoplay</span> <span>playsInline</span> <span>muted</span>&gt;</span><span>&lt;/<span>video</span>&gt;</span>\n<span>&lt;<span>script</span>&gt;</span>\nlet blobs = [];\nlet stream;\nlet mediaRecorder;\nasync function startRecording()\n{\n    stream = await navigator.mediaDevices.getUserMedia({ audio: true, video: true });\n    mediaRecorder = new MediaRecorder(stream);\n    mediaRecorder.ondataavailable = (event) =&gt; {\n       // Let's append blobs for now, we could also upload them to the network.\n       if (event.data)\n            blobs.push(event.data);\n    }\n    mediaRecorder.onstop = doPreview;\n    // Let's receive 1 second blobs\n    mediaRecorder.start(1000);\n}\nfunction endRecording()\n{\n    // Let's stop capture and recording\n    mediaRecorder.stop();\n    stream.getTracks().forEach(track =&gt; track.stop());\n}\nfunction doPreview()\n{\n    if (!blobs.length)\n        return;\n    // Let's concatenate blobs to preview the recorded content\n    video.src = URL.createObjectURL(new Blob(blobs, { type: mediaRecorder.mimeType }));\n}\n<span>&lt;/<span>script</span>&gt;</span>\n<span>&lt;/<span>body</span>&gt;</span>\n<span>&lt;/<span>html</span>&gt;</span>\n</code></pre><p>Future work may extend the support to additional codecs as well as supporting options like video/audio bitrates.</p><h2>getUserMedia in WKWebView</h2><p>Speaking of Safari in latest iOS 14.3 beta and local capture, navigator.mediaDevices.getUserMedia can now be exposed to WKWebView applications. navigator.mediaDevices.getUserMedia is automatically exposed if the embedding application is able to natively capture either audio or video. Please refer to <a href=\"https://developer.apple.com/documentation/avfoundation/cameras_and_media_capture/requesting_authorization_for_media_capture_on_ios\">Apple documentation</a> to meet these requirements. Access to camera and microphone is gated by a user prompt similar to Safari and SafariViewController prompts. We hope to extend WKWebView APIs to allow applications to further control their camera and microphone management in future releases.</p><p>We hope you will like these new features. As always, please let us know if you encounter any bugs (or if you have ideas for future enhancements) by filing bugs on <a href=\"https://bugs.webkit.org/\">bugs.webkit.org</a>.</p></div></article></div>","author":"","siteTitle":"Blog â€“ WebKit","siteHash":"7f8dbea0b8f53db2e11a2faa08c6dca9954c01638d09a2ce585b77a60d10f7a1","entryHash":"cd0e3703ede276f1e6ba3ea2f344529cf29903ab55ce06ee10acf40bbd91dcd5","category":"Tech"}